{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proto-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoVGAqfhCwsa"
      },
      "source": [
        "**0. Melakukan autentikasi pada Google**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-yA985Dga_r"
      },
      "source": [
        "# import library untuk meload file dari google drive\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "# import untuk keperluan auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# melakukan auth\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyO57ug3t9ks",
        "outputId": "d2d29bfd-7e2a-4194-b428-efbcdf8d007c"
      },
      "source": [
        "# melakukan mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIVdCVhXCnoo"
      },
      "source": [
        "**1. Membaca dataset yang berbentuk CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "N6iw7KB5uGHj",
        "outputId": "23d953f6-a84c-458d-9e7a-1a231787f597"
      },
      "source": [
        "# import library untuk membaca dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# membaca dataset dari file google drive\n",
        "path = \"/content/drive/MyDrive/AI_2021/datasetv1.csv\"\n",
        "df = pd.read_csv(path, sep=',', encoding='utf-8')\n",
        "\n",
        "# menampilkan dataset\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>&lt;USERNAME&gt; TOLOL!! Gak ada hubungan nya kegug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>Geblek lo tata...cowo bgt dibela2in balikan......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>Kmrn termewek2 skr lengket lg duhhh kok labil ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>Intinya kalau kesel dengan ATT nya, gausah ke ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id sentiment                                               text\n",
              "0   1  negative   <USERNAME> TOLOL!! Gak ada hubungan nya kegug...\n",
              "1   2  negative  Geblek lo tata...cowo bgt dibela2in balikan......\n",
              "2   3  negative  Kmrn termewek2 skr lengket lg duhhh kok labil ...\n",
              "3   4  negative  Intinya kalau kesel dengan ATT nya, gausah ke ...\n",
              "4   5  negative  hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN9XuPWDGzQM"
      },
      "source": [
        "**2. Membersihkan data : Casefolding**\n",
        "\n",
        "Tahapan pertama dari preprocessing data dan casefolding:\n",
        "1. Menghilangkan tanda baca, emoticon, hashtag, atau tagging username\n",
        "2. Mengubah semua kata menjadi lowercase (casefolding), jadi ketika ada kata yang sama namun memiliki susunan kapital yang berbeda, maka kata tersebut akan diseragamkan menjadi kata yang sama."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "zly_WO38woGH",
        "outputId": "83cf1353-0640-4e39-e0cf-7b7d731c3ef4"
      },
      "source": [
        "# import library regex\n",
        "import re\n",
        "\n",
        "# casefolding pada dataset\n",
        "def dataset_casefolding(stc):\n",
        "  stc = re.sub(\"<USERNAME>\", \"\", stc)\n",
        "  stc = stc.lower()\n",
        "  stc = stc.strip(\" \")\n",
        "  stc = re.sub(r'[?|$|.|2!_:\")(-+,]', '', stc)\n",
        "  \n",
        "  return stc\n",
        "\n",
        "# mengapply pada dataset\n",
        "df['text'] = df['text'].apply(dataset_casefolding)\n",
        "\n",
        "# menampilkan dataset\n",
        "df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>tolol gak ada hubungan nya keguguran dgn pake ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>geblek lo tatacowo bgt dibelain balikanhadewwn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>kmrn termewek skr lengket lg duhhh kok labil b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>intinya kalau kesel dengan att nya gausah ke a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>hadewwwww permpuan itu lgsakit jiwaknp harus d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>negative</td>\n",
              "      <td>pantesan di tinggalin laki ya lakinya juga mik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>negative</td>\n",
              "      <td>kebiasaan balajaer nyampah d ig para artissuka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>negative</td>\n",
              "      <td>krn sebagian besar rakyat indonesia itu bodoh ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>negative</td>\n",
              "      <td>ayu janda bego pny suami kpn nikah laginya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>negative</td>\n",
              "      <td>anyiennnnggg suaranya ancur banget lebih merdu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id sentiment                                               text\n",
              "0   1  negative  tolol gak ada hubungan nya keguguran dgn pake ...\n",
              "1   2  negative  geblek lo tatacowo bgt dibelain balikanhadewwn...\n",
              "2   3  negative  kmrn termewek skr lengket lg duhhh kok labil b...\n",
              "3   4  negative  intinya kalau kesel dengan att nya gausah ke a...\n",
              "4   5  negative  hadewwwww permpuan itu lgsakit jiwaknp harus d...\n",
              "5   6  negative  pantesan di tinggalin laki ya lakinya juga mik...\n",
              "6   7  negative  kebiasaan balajaer nyampah d ig para artissuka...\n",
              "7   8  negative  krn sebagian besar rakyat indonesia itu bodoh ...\n",
              "8   9  negative         ayu janda bego pny suami kpn nikah laginya\n",
              "9  10  negative  anyiennnnggg suaranya ancur banget lebih merdu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6APTAv2KdVq"
      },
      "source": [
        "**3. Melakukan tokenizing pada dataset**\n",
        "\n",
        "Yaitu memecah kalimat yang perada pada *panda series* menjadi kata-kata yang unik (tidak berulang)\n",
        "\n",
        "\n",
        "Misal kata-kata = ['aku akan pergi namun aku tidak akan pulang']\n",
        "\n",
        "menjadi = [aku, akan, pergi, namun, tidak, pulang]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "LYp53AbU8QlZ",
        "outputId": "d9a1f934-2a2d-4662-f612-6869550105b4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "\n",
        "# proses tokenizing\n",
        "def tokenizing(stc):\n",
        "  stc = [stc]\n",
        "  token = Tokenizer()         # buat instance tokenizer\n",
        "  token.fit_on_texts(stc)     # load text di instance nya\n",
        "\n",
        "  return list(token.index_word.values())\n",
        "\n",
        "df['text'] = df['text'].apply(tokenizing)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>[gak, nya, ada, hubungan, lo, tolol, keguguran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>[geblek, lo, tatacowo, bgt, dibelain, balikanh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>[kmrn, termewek, skr, lengket, lg, duhhh, kok,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>[dia, sama, anaknya, anak, orang, bener, benci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>[hadewwwww, permpuan, itu, lgsakit, jiwaknp, h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id sentiment                                               text\n",
              "0   1  negative  [gak, nya, ada, hubungan, lo, tolol, keguguran...\n",
              "1   2  negative  [geblek, lo, tatacowo, bgt, dibelain, balikanh...\n",
              "2   3  negative  [kmrn, termewek, skr, lengket, lg, duhhh, kok,...\n",
              "3   4  negative  [dia, sama, anaknya, anak, orang, bener, benci...\n",
              "4   5  negative  [hadewwwww, permpuan, itu, lgsakit, jiwaknp, h..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYGuDI-CPDWG"
      },
      "source": [
        "**3. Proses menghapus stopword**\n",
        "\n",
        "Stopword ialah ata umum yang tidak memberikan informasi penting (yang biasanya tidak diacuhkan atau dibuang (yang, di, ke)). Dalam tahapan ini, kata-kata yang termasuk dalam stopword akan dihilangkan. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "Ubcz_F9rLSth",
        "outputId": "432668b1-a744-43de-f7f2-60658982d12b"
      },
      "source": [
        "# process filtering stopword (Kata umum yang tidak memberikan informasi penting (yang biasanya tidak diacuhkan atau dibuang, misalnya dalam proses pembuatan indeks))\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def stopwords_removal(stc):\n",
        "  filtering = stopwords.words('indonesian', 'english')\n",
        "  filtering.append('yg')\n",
        "  x = []\n",
        "  data = []\n",
        "\n",
        "  def if_nin(x):\n",
        "    if x in filtering:\n",
        "      return False\n",
        "\n",
        "    return True\n",
        "\n",
        "  fit = filter(if_nin, stc)\n",
        "  for x in fit:\n",
        "    data.append(x)\n",
        "\n",
        "  return data\n",
        "\n",
        "df['text'] = df['text'].apply(stopwords_removal)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>[gak, nya, hubungan, lo, tolol, keguguran, dgn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>[geblek, lo, tatacowo, bgt, dibelain, balikanh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>[kmrn, termewek, skr, lengket, lg, duhhh, labi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>[anaknya, anak, orang, bener, benci, intinya, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>[hadewwwww, permpuan, lgsakit, jiwaknp, jd, pe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id sentiment                                               text\n",
              "0   1  negative  [gak, nya, hubungan, lo, tolol, keguguran, dgn...\n",
              "1   2  negative  [geblek, lo, tatacowo, bgt, dibelain, balikanh...\n",
              "2   3  negative  [kmrn, termewek, skr, lengket, lg, duhhh, labi...\n",
              "3   4  negative  [anaknya, anak, orang, bener, benci, intinya, ...\n",
              "4   5  negative  [hadewwwww, permpuan, lgsakit, jiwaknp, jd, pe..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l43Y-X0aQ2wN"
      },
      "source": [
        "**4. Proses stemming**\n",
        "\n",
        "Yaitu proses dimana kata-kata yang berada di dalam kalimat pada dataset, akan diubah menjadi kata dasarnya. \n",
        "\n",
        "Contoh = hubungan menjadi hubung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "KSlxaM3CQACR",
        "outputId": "1cd10ad5-f769-41c3-ec8f-c5ef19e79469"
      },
      "source": [
        "# proses stemming\n",
        "! pip install Sastrawi\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "def stemming(stc):\n",
        "  factory = StemmerFactory()\n",
        "  stemmer = factory.create_stemmer()\n",
        "  do = []\n",
        "\n",
        "  for word in stc:\n",
        "    dt = stemmer.stem(word)\n",
        "    do.append(dt)\n",
        "\n",
        "  d_clean = []\n",
        "  d_clean = \" \".join(do)\n",
        "\n",
        "  return d_clean\n",
        "  \n",
        "df['text'] = df['text'].apply(stemming)\n",
        "df.head()\n",
        "\n",
        "df.to_csv('data_clean.csv', index=False)\n",
        "data_clean = pd.read_csv('data_clean.csv', encoding='latin1')\n",
        "data_clean.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 10.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20kB 12.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 174kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 184kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 194kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 204kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 5.6MB/s \n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>gak nya hubung lo tolol gugur dgn pake hijab s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>geblek lo tatacowo bgt bain balikanhadewwntar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>kmrn mewek skr lengket lg duhhh labil bgt sih ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>anak anak orang bener benci inti kesel att nya...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>hadewwwww permpuan lgsakit jiwaknp jd peran ut...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id sentiment                                               text\n",
              "0   1  negative  gak nya hubung lo tolol gugur dgn pake hijab s...\n",
              "1   2  negative  geblek lo tatacowo bgt bain balikanhadewwntar ...\n",
              "2   3  negative  kmrn mewek skr lengket lg duhhh labil bgt sih ...\n",
              "3   4  negative  anak anak orang bener benci inti kesel att nya...\n",
              "4   5  negative  hadewwwww permpuan lgsakit jiwaknp jd peran ut..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG0P9CwjXEP7"
      },
      "source": [
        "data_clean = data_clean.astype({'sentiment': 'category'})\n",
        "data_clean = data_clean.astype({'text': 'string'})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtrP3vpTRznt"
      },
      "source": [
        "**6. Proses Pembobotan Kata**\n",
        "\n",
        "Menggunakan TfidfVectorizer, untuk memboboti suatu kata. Semakin banyak kata yang terdapat pada kalimat, maka bobot akan semakin besar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SiXT6T7Xw7T",
        "outputId": "8a5f6e4b-4170-4a76-db71-0da52a8f1c84"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf = TfidfVectorizer()\n",
        "text_tf = tf.fit_transform(data_clean['text'].astype('U'))\n",
        "text_tf"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<400x2602 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 6133 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWzfVZdyThsC"
      },
      "source": [
        "**7. Memisah data, menjadi training dan test data dengan proporsi 80:20**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAjyb0HoYlFp"
      },
      "source": [
        "# splitting data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(text_tf, data_clean['sentiment'], test_size=0.2, random_state=42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HG_JEoUUgso"
      },
      "source": [
        "**8. Menjalankan model naive bayes**\n",
        "\n",
        "- Membuat instance model naive bayes, lalu memasukkan data traininnya (sebesar 80 persen dari keseluruhan data).\n",
        "\n",
        "- Kemudian setelah di training, akan dilakukan prengujian (test) pada model, dengan memasukkan data testingnya\n",
        "\n",
        "- Setelah hasil testing diperoleh, kemudian akan dihitungkan keakuratannya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3WknhISZ5H2",
        "outputId": "40a720aa-971c-4f4b-bf1d-638cec168921"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "clf = MultinomialNB().fit(X_train, y_train)\n",
        "predicted = clf.predict(X_test)\n",
        "\n",
        "print(\"MultinomialNB accurancy : \", accuracy_score(y_test, predicted))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB accurancy :  0.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zf6EujFHwAl"
      },
      "source": [
        "**9. Testing model**\n",
        "\n",
        "- Secara manual\n",
        "- Dengan csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIaoS29y2E5c",
        "outputId": "c31f8331-b214-4905-aaf9-6b126c3def82"
      },
      "source": [
        "# Testing input manual\n",
        "inpx = input('Masukkan kalimat\\t:\\t')\n",
        "in_pds = pd.Series(np.array([inpx]))\n",
        "in_tf = tf.transform(in_pds)\n",
        "\n",
        "clf.predict(in_tf)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Masukkan kalimat\t:\tsampah kali negri ini!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsLD5lN_HsZu",
        "outputId": "f87b8a21-ba8a-4dae-ba3b-e2425204329c"
      },
      "source": [
        "# Testing dengan csv\n",
        "\n",
        "# membaca dataset dari file google drive\n",
        "import collections\n",
        "\n",
        "path = \"/content/drive/MyDrive/AI_2021/trydata.csv\"\n",
        "df2 = pd.read_csv(path, sep=',', encoding='utf-8')\n",
        "df2_raw = pd.read_csv(path, sep=',', encoding='utf-8')['values']\n",
        "\n",
        "# casefolding\n",
        "df2['values'] = df2['values'].apply(dataset_casefolding)\n",
        "# tokenizing\n",
        "df2['values'] = df2['values'].apply(tokenizing)\n",
        "# menghilangkan stopwords\n",
        "df2['values'] = df2['values'].apply(stopwords_removal)\n",
        "# stemming\n",
        "df2['values'] = df2['values'].apply(stemming)\n",
        "df2.to_csv('data_clean2.csv', index=False)\n",
        "data_clean2 = pd.read_csv('data_clean2.csv', encoding='latin1')\n",
        "# pembobotan kata\n",
        "text_tf2 = tf.transform(data_clean2['values'].astype('U'))\n",
        "\n",
        "# prediksi melalui model\n",
        "predictions = clf.predict(text_tf2)\n",
        "tweets_len = len(predictions)\n",
        "\n",
        "# hitung presentase\n",
        "tweets_p = np.count_nonzero(predictions == 'positive')\n",
        "tweets_n = np.count_nonzero(predictions == 'negative')\n",
        "c = (tweets_p/tweets_len) * 100\n",
        "prec_p = (tweets_p/tweets_len) * 100\n",
        "prec_n = (tweets_n/tweets_len) * 100\n",
        "\n",
        "print('Berdasarkan username Twitter yang Anda berikan, kami telah menganalisis kemungkinan kondisi emosional anak Anda beberapa waktu belakangan ini, memiliki presentase sebagai berikut:\\n')\n",
        "print('positive : ', prec_p)\n",
        "print('negative : ', prec_n, '\\n')\n",
        "if prec_p > prec_n:\n",
        "  print('Maka dari itu, sejauh ini keadaan emosional anak Bapak/Ibu berada di kondisi mental yang positif.')\n",
        "elif prec_p < prec_n:\n",
        "  print('Maka dari itu kami sarankan Bapak/Ibu agar lebih meluangkan waktunya bersama anak Anda supaya lebih mengerti kondisi emosionalnya.')\n",
        "else:\n",
        "  print('Sejauh ini tweet yang diposting oleh anak Anda memiliki memiliki presentasi yang setara, kami menyarankan agar Anda lebih memperhatikan anak anda agar kondisi emosional anak Anda kembali stabil')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Berdasarkan username Twitter yang Anda berikan, kami telah menganalisis kemungkinan kondisi emosional anak Anda beberapa waktu belakangan ini, memiliki presentase sebagai berikut:\n",
            "\n",
            "positive :  20.0\n",
            "negative :  80.0 \n",
            "\n",
            "Maka dari itu kami sarankan Bapak/Ibu agar lebih meluangkan waktunya bersama anak Anda supaya lebih mengerti kondisi emosionalnya.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}